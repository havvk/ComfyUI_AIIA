"""
AIIA Text Splitter â€” å•äººæ–‡æœ¬æŒ‰æ ‡ç‚¹æ‹†åˆ†ä¸º dialogue_json
[v1.13.0 New]

å°†é•¿æ–‡æœ¬æŒ‰å¥å·ã€é—®å·ã€æ„Ÿå¹å·ç­‰æ ‡ç‚¹æ‹†åˆ†ä¸ºæ ‡å‡† dialogue_json æ ¼å¼ï¼Œ
å¯ç›´æ¥æ¥å…¥ Emotion Annotator â†’ TTS ç®¡çº¿ã€‚

æ”¯æŒçŸ­å¥åˆå¹¶ï¼ˆé¿å…ç¢ç‰‡ï¼‰å’Œé•¿å¥æ‹†åˆ†ï¼ˆé¿å… TTS å•å¥è¿‡é•¿ï¼‰ã€‚
"""

import json
import re


class AIIA_Text_Splitter:
    """
    å°†çº¯æ–‡æœ¬æŒ‰æ ‡ç‚¹æ‹†åˆ†ä¸º dialogue_json æ ¼å¼ã€‚

    æ”¯æŒä¸‰ç§æ‹†åˆ†æ¨¡å¼ï¼š
    - auto: ä¸­è‹±æ–‡è‡ªåŠ¨ï¼ŒæŒ‰å¥æœ«æ ‡ç‚¹æ‹†åˆ† + çŸ­å¥åˆå¹¶ + é•¿å¥æ‹†åˆ†
    - by_sentence: ä»…æŒ‰å¥å·/é—®å·/æ„Ÿå¹å·æ‹†åˆ†
    - by_line: æŒ‰æ¢è¡Œæ‹†åˆ†
    """

    NODE_NAME = "AIIA Text Splitter"

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "text": ("STRING", {
                    "multiline": True,
                    "default": "",
                    "tooltip": "å¾…æ‹†åˆ†çš„æ–‡æœ¬ã€‚æ”¯æŒå¤šæ®µè½ã€å¤šè¡Œã€‚"
                }),
                "speaker_name": ("STRING", {
                    "default": "Narrator",
                    "tooltip": "è¯´è¯äººåç§°ï¼Œå†™å…¥ dialogue_json çš„ speaker å­—æ®µ"
                }),
                "split_mode": (["auto", "by_sentence", "by_line"], {
                    "default": "auto",
                    "tooltip": "æ‹†åˆ†æ¨¡å¼ï¼š\n"
                               "  auto: æŒ‰å¥æœ«æ ‡ç‚¹æ‹†åˆ† + çŸ­å¥åˆå¹¶ + é•¿å¥å†æ‹†\n"
                               "  by_sentence: ä»…æŒ‰å¥å·/é—®å·/æ„Ÿå¹å·æ‹†åˆ†\n"
                               "  by_line: æŒ‰æ¢è¡Œæ‹†åˆ†"
                }),
            },
            "optional": {
                "min_chars": ("INT", {
                    "default": 4,
                    "min": 1,
                    "max": 50,
                    "tooltip": "æœ€å°å­—ç¬¦æ•°ã€‚çŸ­äºæ­¤çš„å¥å­åˆå¹¶åˆ°å‰ä¸€å¥ã€‚"
                }),
                "max_chars": ("INT", {
                    "default": 100,
                    "min": 20,
                    "max": 500,
                    "tooltip": "æœ€å¤§å­—ç¬¦æ•°ã€‚è¶…é•¿å¥å­åœ¨é€—å·/åˆ†å·å¤„å¼ºåˆ¶æ‹†åˆ†ã€‚"
                }),
            }
        }

    RETURN_TYPES = ("STRING", "INT")
    RETURN_NAMES = ("dialogue_json", "sentence_count")
    FUNCTION = "split_text"
    CATEGORY = "AIIA/Podcast"

    def split_text(self, text, speaker_name="Narrator", split_mode="auto",
                   min_chars=4, max_chars=100):
        """æ‹†åˆ†æ–‡æœ¬ä¸º dialogue_json æ ¼å¼ã€‚"""

        if not text or not text.strip():
            empty = json.dumps([], ensure_ascii=False)
            return (empty, 0)

        text = text.strip()

        if split_mode == "by_line":
            raw_sentences = self._split_by_line(text)
        elif split_mode == "by_sentence":
            raw_sentences = self._split_by_sentence(text)
        else:  # auto
            raw_sentences = self._split_auto(text, min_chars, max_chars)

        # æ„å»º dialogue_json
        dialogue = []
        for sent in raw_sentences:
            sent = sent.strip()
            if not sent:
                continue
            dialogue.append({
                "type": "speech",
                "speaker": speaker_name,
                "text": sent,
                "emotion": None
            })

        result = json.dumps(dialogue, ensure_ascii=False, indent=2)
        return (result, len(dialogue))

    def _split_by_line(self, text):
        """æŒ‰æ¢è¡Œæ‹†åˆ†ï¼Œç©ºè¡Œè·³è¿‡ã€‚"""
        return [line.strip() for line in text.split("\n") if line.strip()]

    def _split_by_sentence(self, text):
        """ä»…æŒ‰å¥æœ«æ ‡ç‚¹æ‹†åˆ†ï¼ˆå¥å·ã€é—®å·ã€æ„Ÿå¹å·ã€çœç•¥å·ï¼‰ã€‚"""
        # å…ˆæŒ‰æ¢è¡Œåˆ†æ®µï¼Œå†æ®µå†…æŒ‰æ ‡ç‚¹æ‹†åˆ†
        paragraphs = [p.strip() for p in text.split("\n") if p.strip()]
        sentences = []
        for para in paragraphs:
            parts = self._split_at_sentence_end(para)
            sentences.extend(parts)
        return sentences

    def _split_auto(self, text, min_chars, max_chars):
        """
        æ™ºèƒ½æ‹†åˆ†ï¼š
        1. æŒ‰æ¢è¡Œåˆ†æ®µ
        2. æ®µå†…æŒ‰å¥æœ«æ ‡ç‚¹æ‹†åˆ†
        3. çŸ­å¥åˆå¹¶
        4. é•¿å¥åœ¨é€—å·/åˆ†å·å¤„å†æ‹†
        """
        paragraphs = [p.strip() for p in text.split("\n") if p.strip()]
        all_sentences = []

        for para in paragraphs:
            # Step 1: æŒ‰å¥æœ«æ ‡ç‚¹æ‹†åˆ†
            raw = self._split_at_sentence_end(para)

            # Step 2: çŸ­å¥åˆå¹¶
            merged = self._merge_short(raw, min_chars)

            # Step 3: é•¿å¥æ‹†åˆ†
            final = []
            for sent in merged:
                if len(sent) > max_chars:
                    final.extend(self._split_long(sent, max_chars))
                else:
                    final.append(sent)

            all_sentences.extend(final)

        return all_sentences

    def _split_at_sentence_end(self, text):
        """
        åœ¨å¥æœ«æ ‡ç‚¹å¤„æ‹†åˆ†ï¼Œä¿ç•™æ ‡ç‚¹åœ¨å‰ä¸€å¥æœ«å°¾ã€‚
        æ”¯æŒï¼šã€‚ï¼ï¼Ÿ!?  ä»¥åŠçœç•¥å· â€¦â€¦ / ...
        """
        # æŒ‰å¥æœ«æ ‡ç‚¹æ‹†åˆ†ï¼Œä¿ç•™åˆ†éš”ç¬¦
        # åŒ¹é…ï¼šå¥å·/é—®å·/æ„Ÿå¹å·ï¼ˆä¸­è‹±æ–‡ï¼‰ï¼Œä»¥åŠçœç•¥å·
        parts = re.split(r'((?:\.{3}|â€¦{1,2}|[ã€‚ï¼ï¼Ÿ!?]))', text)

        sentences = []
        buffer = ""
        for i, part in enumerate(parts):
            if i % 2 == 0:
                # æ­£æ–‡éƒ¨åˆ†
                buffer += part
            else:
                # æ ‡ç‚¹éƒ¨åˆ†ï¼Œé™„åŠ åˆ° buffer
                buffer += part
                if buffer.strip():
                    sentences.append(buffer.strip())
                buffer = ""

        # å¤„ç†æœ«å°¾æ²¡æœ‰æ ‡ç‚¹çš„æ®‹ä½™
        if buffer.strip():
            sentences.append(buffer.strip())

        return sentences

    def _merge_short(self, sentences, min_chars):
        """å°†çŸ­äº min_chars çš„å¥å­åˆå¹¶åˆ°å‰ä¸€å¥ã€‚"""
        if not sentences:
            return sentences

        merged = [sentences[0]]
        for sent in sentences[1:]:
            if len(sent) < min_chars and merged:
                # åˆå¹¶åˆ°å‰ä¸€å¥
                merged[-1] = merged[-1] + sent
            else:
                merged.append(sent)

        return merged

    def _split_long(self, text, max_chars):
        """
        å°†è¶…é•¿å¥å­åœ¨é€—å·/åˆ†å·/é¡¿å·å¤„æ‹†åˆ†ã€‚
        å°½é‡é è¿‘ max_chars çš„ä½ç½®åˆ‡ï¼Œé¿å…å¤ªç¢ã€‚
        """
        # å¯é€‰æ‹†åˆ†ç‚¹ï¼šé€—å·ã€åˆ†å·ã€é¡¿å·ï¼ˆä¸­è‹±æ–‡ï¼‰
        split_points = []
        for i, ch in enumerate(text):
            if ch in 'ï¼Œ,ï¼›;ã€':
                split_points.append(i)

        if not split_points:
            # æ²¡æœ‰å¯æ‹†åˆ†ç‚¹ï¼ŒåŸæ ·è¿”å›
            return [text]

        result = []
        start = 0
        for point in split_points:
            segment = text[start:point + 1]
            if len(segment) >= max_chars // 2:
                # å¤Ÿé•¿äº†ï¼Œåˆ‡ä¸€åˆ€
                result.append(segment.strip())
                start = point + 1

        # è¿½åŠ å‰©ä½™éƒ¨åˆ†
        remainder = text[start:].strip()
        if remainder:
            if result and len(remainder) < max_chars // 4:
                # æ®‹ä½™å¤ªçŸ­ï¼Œåˆå¹¶åˆ°æœ€åä¸€æ®µ
                result[-1] = result[-1] + remainder
            else:
                result.append(remainder)

        return result if result else [text]


# === ComfyUI Registration ===
NODE_CLASS_MAPPINGS = {
    "AIIA_Text_Splitter": AIIA_Text_Splitter,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "AIIA_Text_Splitter": "ğŸ’¬ AIIA Text Splitter",
}
