import torch
import os
import json
import tempfile
import numpy as np
import soundfile as sf
import folder_paths

# --- æ¨¡å‹è·¯å¾„åˆå§‹åŒ– ---
_FUNASR_MODELS_DIR = None
_AVAILABLE_MODELS = {}

try:
    _models_base = os.path.join(folder_paths.base_path, "models", "funasr")
    if os.path.isdir(_models_base):
        _FUNASR_MODELS_DIR = _models_base
        for entry in os.listdir(_models_base):
            full_path = os.path.join(_models_base, entry)
            if os.path.isdir(full_path):
                _AVAILABLE_MODELS[entry] = full_path
                print(f"[AIIA ASR] å‘ç°æ¨¡å‹: {entry} -> {full_path}")
    else:
        print(f"[AIIA ASR] è­¦å‘Š: funasr æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {_models_base}")
except Exception as e:
    print(f"[AIIA ASR] æ¨¡å‹è·¯å¾„åˆå§‹åŒ–é”™è¯¯: {e}")


class AIIA_ASR:
    """é€šç”¨ ASR è¯­éŸ³è¯†åˆ«èŠ‚ç‚¹ï¼ŒåŸºäº FunASRï¼Œæ”¯æŒå­—çº§æ—¶é—´æˆ³è¾“å‡ºã€‚"""

    NODE_NAME = "AIIA ASR"
    _model_cache = {}  # ç±»çº§åˆ«æ¨¡å‹ç¼“å­˜: {model_key: model_instance}

    @classmethod
    def INPUT_TYPES(cls):
        model_choices = list(_AVAILABLE_MODELS.keys()) if _AVAILABLE_MODELS else ["NO_MODELS_FOUND"]
        default_model = "paraformer-zh" if "paraformer-zh" in _AVAILABLE_MODELS else model_choices[0]

        return {
            "required": {
                "audio": ("AUDIO",),
                "model": (model_choices, {"default": default_model}),
            },
            "optional": {
                "device": (["cuda", "cpu"], {"default": "cuda"}),
                "batch_size_s": ("INT", {
                    "default": 300, "min": 1, "max": 3600, "step": 10,
                    "tooltip": "ä»¥ç§’ä¸ºå•ä½çš„åŠ¨æ€ batch å¤§å°ã€‚è¶Šå¤§è¶Šå¿«ä½†å ç”¨æ›´å¤šæ˜¾å­˜ã€‚"
                }),
                "hotword": ("STRING", {
                    "default": "",
                    "tooltip": "çƒ­è¯åˆ—è¡¨ï¼Œæ¯è¡Œä¸€ä¸ªè¯ã€‚æé«˜è¿™äº›è¯çš„è¯†åˆ«å‡†ç¡®ç‡ã€‚"
                }),
            }
        }

    RETURN_TYPES = ("ASR_RESULT", "STRING",)
    RETURN_NAMES = ("asr_result", "text",)
    FUNCTION = "recognize"
    CATEGORY = "AIIA/Audio"

    def _ensure_model(self, model_name: str, device: str):
        """åŠ è½½æˆ–ä»ç¼“å­˜è·å–æ¨¡å‹å®ä¾‹ã€‚"""
        cache_key = f"{model_name}_{device}"
        if cache_key in self._model_cache:
            print(f"[{self.NODE_NAME}] ä½¿ç”¨ç¼“å­˜æ¨¡å‹: {model_name} on {device}")
            return self._model_cache[cache_key]

        model_path = _AVAILABLE_MODELS.get(model_name)
        if not model_path:
            raise RuntimeError(f"æ¨¡å‹ '{model_name}' æœªæ‰¾åˆ°ã€‚å¯ç”¨æ¨¡å‹: {list(_AVAILABLE_MODELS.keys())}")

        from funasr import AutoModel

        # æ£€æµ‹æ˜¯å¦ä¸º SenseVoice ç³»åˆ—ï¼ˆéœ€è¦ trust_remote_codeï¼‰
        is_sensevoice = "sensevoice" in model_name.lower()

        print(f"[{self.NODE_NAME}] åŠ è½½æ¨¡å‹: {model_path} on {device}...")
        model = AutoModel(
            model=model_path,
            device=device,
            disable_update=True,
            trust_remote_code=is_sensevoice,
        )
        print(f"[{self.NODE_NAME}] æ¨¡å‹åŠ è½½å®Œæˆã€‚")

        self._model_cache[cache_key] = model
        return model

    def _audio_to_numpy(self, audio: dict) -> tuple:
        """å°† ComfyUI AUDIO æ ¼å¼è½¬æ¢ä¸º 16kHz mono numpy æ•°ç»„ã€‚"""
        waveform = audio["waveform"]  # (batch, channels, samples)
        sample_rate = audio["sample_rate"]

        # å–ç¬¬ä¸€ä¸ª batch
        if waveform.ndim == 3:
            wav = waveform[0]
        else:
            wav = waveform

        # è½¬ mono
        if wav.ndim == 2 and wav.shape[0] > 1:
            wav = wav.mean(dim=0)
        elif wav.ndim == 2:
            wav = wav.squeeze(0)

        wav_np = wav.cpu().numpy().astype(np.float32)

        # é‡é‡‡æ ·åˆ° 16kHzï¼ˆFunASR è¦æ±‚ï¼‰
        if sample_rate != 16000:
            try:
                import torchaudio.functional as F
                wav_tensor = torch.from_numpy(wav_np).unsqueeze(0)
                wav_resampled = F.resample(wav_tensor, sample_rate, 16000)
                wav_np = wav_resampled.squeeze(0).numpy()
                print(f"[{self.NODE_NAME}] é‡é‡‡æ ·: {sample_rate}Hz -> 16000Hz")
            except ImportError:
                # å¦‚æœ torchaudio ä¸å¯ç”¨ï¼Œå†™ä¸´æ—¶æ–‡ä»¶è®© FunASR è‡ªè¡Œå¤„ç†
                print(f"[{self.NODE_NAME}] è­¦å‘Š: torchaudio ä¸å¯ç”¨ï¼Œå°è¯•ç›´æ¥ä¼ å…¥éŸ³é¢‘")
            sample_rate = 16000

        return wav_np, sample_rate

    def recognize(self, audio, model, device="cuda", batch_size_s=300, hotword=""):
        log = f"[{self.NODE_NAME}]"

        if model == "NO_MODELS_FOUND":
            error_result = {
                "text": "",
                "words": [],
                "error": "æœªæ‰¾åˆ° FunASR æ¨¡å‹ã€‚è¯·å°†æ¨¡å‹æ”¾åœ¨ ComfyUI/models/funasr/ ç›®å½•ä¸‹ã€‚"
            }
            return (error_result, "")

        # éªŒè¯éŸ³é¢‘
        if audio is None or "waveform" not in audio:
            error_result = {"text": "", "words": [], "error": "è¾“å…¥éŸ³é¢‘æ— æ•ˆ"}
            return (error_result, "")

        wav_np, sr = self._audio_to_numpy(audio)
        duration = len(wav_np) / sr
        print(f"{log} éŸ³é¢‘æ—¶é•¿: {duration:.2f}s, é‡‡æ ·ç‡: {sr}Hz")

        if duration < 0.1:
            print(f"{log} éŸ³é¢‘å¤ªçŸ­ ({duration:.3f}s)ï¼Œè·³è¿‡è¯†åˆ«")
            return ({"text": "", "words": []}, "")

        # åŠ è½½æ¨¡å‹
        asr_model = self._ensure_model(model, device)

        # æ„å»ºç”Ÿæˆå‚æ•°
        generate_kwargs = {
            "input": wav_np,
            "batch_size_s": batch_size_s,
        }

        # çƒ­è¯æ”¯æŒï¼ˆä»… Paraformer æ”¯æŒï¼‰
        if hotword and hotword.strip() and "paraformer" in model.lower():
            generate_kwargs["hotword"] = hotword.strip()
            print(f"{log} ä½¿ç”¨çƒ­è¯: {hotword.strip()[:50]}...")

        # SenseVoice ç‰¹æ®Šå‚æ•°
        if "sensevoice" in model.lower():
            generate_kwargs["language"] = "auto"
            generate_kwargs["use_itn"] = True

        print(f"{log} å¼€å§‹è¯†åˆ«...")
        results = asr_model.generate(**generate_kwargs)

        if not results or len(results) == 0:
            print(f"{log} è¯†åˆ«ç»“æœä¸ºç©º")
            return ({"text": "", "words": []}, "")

        result = results[0]
        raw_text = result.get("text", "")
        raw_timestamps = result.get("timestamp", [])

        # æ„å»º words åˆ—è¡¨
        words = []
        if raw_timestamps and raw_text:
            # FunASR paraformer: text æ˜¯ç©ºæ ¼åˆ†éš”çš„è¯, timestamp æ˜¯ [[start_ms, end_ms], ...]
            text_tokens = raw_text.split()
            if len(text_tokens) == len(raw_timestamps):
                for token, ts in zip(text_tokens, raw_timestamps):
                    words.append({
                        "word": token,
                        "start": round(ts[0] / 1000.0, 3),  # ms -> s
                        "end": round(ts[1] / 1000.0, 3),
                    })
            else:
                print(f"{log} è­¦å‘Š: è¯æ•° ({len(text_tokens)}) ä¸æ—¶é—´æˆ³æ•° ({len(raw_timestamps)}) ä¸åŒ¹é…")
                # å°½åŠ›åŒ¹é…
                for i, ts in enumerate(raw_timestamps):
                    token = text_tokens[i] if i < len(text_tokens) else "?"
                    words.append({
                        "word": token,
                        "start": round(ts[0] / 1000.0, 3),
                        "end": round(ts[1] / 1000.0, 3),
                    })

        # å»æ‰ç©ºæ ¼ï¼Œæ„å»ºå®Œæ•´æ–‡æœ¬
        clean_text = raw_text.replace(" ", "") if raw_text else ""

        asr_result = {
            "text": clean_text,
            "words": words,
        }

        print(f"{log} è¯†åˆ«å®Œæˆ: {len(words)} ä¸ªè¯, æ–‡æœ¬: {clean_text[:80]}...")
        return (asr_result, clean_text)


# --- ComfyUI èŠ‚ç‚¹æ³¨å†Œ ---
NODE_CLASS_MAPPINGS = {
    "AIIA_ASR": AIIA_ASR,
}
NODE_DISPLAY_NAME_MAPPINGS = {
    "AIIA_ASR": "ğŸ™ï¸ AIIA ASR (Word Timestamps)",
}
