"""
AIIA Emotion Annotator - LLM é©±åŠ¨çš„æƒ…æ„Ÿæ ‡æ³¨èŠ‚ç‚¹

ä½¿ç”¨ OpenAI-compatible APIï¼ˆGroq / Ollama / vLLMï¼‰è‡ªåŠ¨ä¸ºå¯¹è¯å‰§æœ¬æ ‡æ³¨æƒ…æ„Ÿã€‚
æ’å…¥ Script Parser å’Œ Dialogue TTS ä¹‹é—´ï¼Œç›´æ¥ä¿®æ”¹ dialogue_json çš„ emotion å­—æ®µã€‚
"""

import json
import os
import urllib.request
import urllib.error
import ssl

# æƒ…æ„Ÿæ ‡ç­¾åˆ—è¡¨ï¼ˆä¸ AIIA_EMOTION_LIST å¯¹é½ï¼Œä½†ä½¿ç”¨è‹±æ–‡ keyï¼‰
EMOTION_TAGS = [
    "neutral", "happy", "sad", "angry", "excited", "gentle",
    "fearful", "surprised", "disappointed", "serious", "calm",
    "romantic", "sarcastic", "proud", "confused", "anxious",
    "disgusted", "nostalgic", "mysterious", "enthusiastic", "lazy",
    "gossip", "innocent", "nervous"
]

# è‹±æ–‡ â†’ ä¸­æ–‡æ˜¾ç¤ºåæ˜ å°„ï¼ˆç”¨äºæ—¥å¿—ï¼‰
EMOTION_DISPLAY = {
    "neutral": "ä¸­æ€§", "happy": "å¼€å¿ƒ", "sad": "æ‚²ä¼¤", "angry": "æ„¤æ€’",
    "excited": "å…´å¥‹", "gentle": "æ¸©æŸ”", "fearful": "ææƒ§", "surprised": "æƒŠè®¶",
    "disappointed": "å¤±æœ›", "serious": "ä¸¥è‚ƒ", "calm": "å¹³é™", "romantic": "æµªæ¼«",
    "sarcastic": "è®½åˆº", "proud": "è‡ªè±ª", "confused": "å›°æƒ‘", "anxious": "ç„¦è™‘",
    "disgusted": "åŒæ¶", "nostalgic": "æ€€æ—§", "mysterious": "ç¥ç§˜",
    "enthusiastic": "çƒ­æƒ…", "lazy": "æ…µæ‡’", "gossip": "å…«å¦", "innocent": "å¤©çœŸ",
    "nervous": "ç´§å¼ "
}

# æƒ…æ„Ÿæ ‡ç­¾ â†’ CosyVoice / Qwen3 å…¼å®¹æ ¼å¼
EMOTION_TO_TAG = {
    "neutral": None,  # neutral ä¸æ³¨å…¥æ ‡ç­¾
    "happy": "Happy", "sad": "Sad", "angry": "Angry", "excited": "Excited",
    "gentle": "Gentle", "fearful": "Fearful", "surprised": "Surprised",
    "disappointed": "Disappointed", "serious": "Serious", "calm": "Calm",
    "romantic": "Romantic", "sarcastic": "Sarcastic", "proud": "Proud",
    "confused": "Confused", "anxious": "Anxious", "disgusted": "Disgusted",
    "nostalgic": "Nostalgic", "mysterious": "Mysterious",
    "enthusiastic": "Enthusiastic", "lazy": "Lazy tone",
    "gossip": "Gossip tone", "innocent": "Innocent", "nervous": "Nervous"
}

PROMPT_TEMPLATE = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æœ‰å£°è¯»ç‰©æƒ…æ„Ÿæ ‡æ³¨å¸ˆã€‚åˆ†æä»¥ä¸‹å¯¹è¯å‰§æœ¬ï¼Œä¸ºæ¯å¥å°è¯æ ‡æ³¨æœ€åˆé€‚çš„æƒ…æ„Ÿã€‚

å¯é€‰æ ‡ç­¾ï¼ˆåªèƒ½ä»ä¸­é€‰ä¸€ä¸ªï¼‰ï¼š
{tags}

è§„åˆ™ï¼š
1. ç»“åˆä¸Šä¸‹æ–‡è¯­å¢ƒæ•´ä½“åˆ¤æ–­ï¼Œä¸è¦åªçœ‹å•å¥
2. æ—¥å¸¸å¯¹è¯ã€é™ˆè¿°å¥å¤šä¸º neutralï¼Œä¸è¦è¿‡åº¦æ ‡æ³¨
3. åªè¾“å‡ºçº¯ JSON æ•°ç»„ï¼Œä¸è¦æœ‰ä»»ä½•è§£é‡Šæ–‡å­—

å‰§æœ¬ï¼š
{lines}

ä¸¥æ ¼æŒ‰æ­¤æ ¼å¼è¾“å‡ºï¼ˆline ä» 0 å¼€å§‹ï¼‰ï¼š
[{{"line":0,"emotion":"neutral"}},{{"line":1,"emotion":"happy"}}]"""

MODEL_LIST = [
    "llama-3.1-8b-instant",
    "llama-3.3-70b-versatile",
    "qwen-qwq-32b",
    "deepseek-r1-distill-llama-70b",
    "gemma2-9b-it",
]


class AIIA_Emotion_Annotator:
    """
    ä½¿ç”¨ LLM è‡ªåŠ¨ä¸ºå¯¹è¯å‰§æœ¬æ ‡æ³¨æƒ…æ„Ÿæ ‡ç­¾ã€‚
    æ”¯æŒ Groq / Ollama / vLLM ç­‰ OpenAI-compatible APIã€‚
    """

    NODE_NAME = "AIIA Emotion Annotator"

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "dialogue_json": ("STRING", {"forceInput": True}),
                "model": (MODEL_LIST, {"default": "llama-3.1-8b-instant"}),
                "override_mode": (["skip_existing", "overwrite_all"], {"default": "skip_existing"}),
            },
            "optional": {
                "api_base_url": ("STRING", {
                    "default": "https://api.groq.com/openai/v1",
                    "tooltip": "OpenAI-compatible API base URL. Examples:\n"
                               "  Groq: https://api.groq.com/openai/v1\n"
                               "  Ollama: http://localhost:11434/v1\n"
                               "  vLLM: http://localhost:8000/v1"
                }),
                "api_key_override": ("STRING", {
                    "default": "",
                    "tooltip": "å¯é€‰ã€‚ç•™ç©ºåˆ™ä½¿ç”¨ç¯å¢ƒå˜é‡ GROQ_API_KEY"
                }),
                "custom_model": ("STRING", {
                    "default": "",
                    "tooltip": "è‡ªå®šä¹‰æ¨¡å‹åï¼ˆè¦†ç›–ä¸‹æ‹‰é€‰æ‹©ï¼‰ï¼Œç”¨äº Ollama/vLLM æœ¬åœ°æ¨¡å‹"
                }),
            }
        }

    RETURN_TYPES = ("STRING", "STRING")
    RETURN_NAMES = ("dialogue_json", "annotation_log")
    FUNCTION = "annotate"
    CATEGORY = "AIIA/Podcast"

    def _get_api_key(self, api_key_override=""):
        """è·å– API Keyï¼šä¼˜å…ˆä½¿ç”¨ overrideï¼Œå¦åˆ™è¯»å–ç¯å¢ƒå˜é‡"""
        if api_key_override and api_key_override.strip():
            return api_key_override.strip()
        key = os.environ.get("GROQ_API_KEY", "")
        if not key:
            # å°è¯•ä» ~/run.sh è¯»å–ï¼ˆå…¼å®¹æœåŠ¡å™¨ç¯å¢ƒï¼‰
            run_sh = os.path.expanduser("~/run.sh")
            if os.path.exists(run_sh):
                try:
                    with open(run_sh, 'r') as f:
                        for line in f:
                            line = line.strip()
                            if line.startswith("export GROQ_API_KEY="):
                                key = line.split("=", 1)[1].strip().strip('"').strip("'")
                                break
                except Exception:
                    pass
        return key

    def _call_llm(self, api_base_url, api_key, model, prompt):
        """è°ƒç”¨ OpenAI-compatible API"""
        log = f"[{self.NODE_NAME}]"
        url = f"{api_base_url.rstrip('/')}/chat/completions"

        payload = {
            "model": model,
            "messages": [{"role": "user", "content": prompt}],
            "temperature": 0.2,
            "max_tokens": 2048,
        }

        headers = {
            "Content-Type": "application/json",
        }
        if api_key:
            headers["Authorization"] = f"Bearer {api_key}"

        data = json.dumps(payload).encode("utf-8")
        req = urllib.request.Request(url, data=data, headers=headers, method="POST")

        # æ”¯æŒè‡ªç­¾åè¯ä¹¦çš„æœ¬åœ°æœåŠ¡
        ctx = ssl.create_default_context()
        if "localhost" in api_base_url or "127.0.0.1" in api_base_url:
            ctx.check_hostname = False
            ctx.verify_mode = ssl.CERT_NONE

        try:
            # è¯»å–ä»£ç†è®¾ç½®ï¼ˆä»ç¯å¢ƒå˜é‡ï¼‰
            proxy_url = os.environ.get("HTTPS_PROXY") or os.environ.get("https_proxy") or os.environ.get("ALL_PROXY")
            if proxy_url and "localhost" not in api_base_url and "127.0.0.1" not in api_base_url:
                proxy_handler = urllib.request.ProxyHandler({
                    "https": proxy_url,
                    "http": proxy_url
                })
                opener = urllib.request.build_opener(
                    proxy_handler,
                    urllib.request.HTTPSHandler(context=ctx)
                )
            else:
                opener = urllib.request.build_opener(
                    urllib.request.HTTPSHandler(context=ctx)
                )

            with opener.open(req, timeout=60) as resp:
                body = json.loads(resp.read().decode("utf-8"))
                content = body["choices"][0]["message"]["content"]
                return content, None
        except urllib.error.HTTPError as e:
            err_body = e.read().decode("utf-8", errors="replace") if e.fp else ""
            return None, f"HTTP {e.code}: {err_body[:200]}"
        except Exception as e:
            return None, f"{type(e).__name__}: {e}"

    def _parse_llm_response(self, raw_text, line_count):
        """ä» LLM å“åº”ä¸­æå– JSON æ•°ç»„"""
        # å°è¯•ç›´æ¥è§£æ
        text = raw_text.strip()

        # å»é™¤ markdown ä»£ç å—åŒ…è£¹
        if text.startswith("```"):
            lines = text.split("\n")
            # å»é¦–å°¾ ```
            if lines[0].startswith("```"):
                lines = lines[1:]
            if lines and lines[-1].strip() == "```":
                lines = lines[:-1]
            text = "\n".join(lines).strip()

        # æå– JSON æ•°ç»„éƒ¨åˆ†
        start = text.find("[")
        end = text.rfind("]")
        if start == -1 or end == -1:
            return None, f"æœªæ‰¾åˆ° JSON æ•°ç»„: {text[:100]}"

        json_str = text[start:end + 1]
        try:
            result = json.loads(json_str)
        except json.JSONDecodeError as e:
            return None, f"JSON è§£æå¤±è´¥: {e}\nåŸå§‹: {json_str[:200]}"

        if not isinstance(result, list):
            return None, f"æœŸæœ› JSON æ•°ç»„ï¼Œå¾—åˆ° {type(result)}"

        # éªŒè¯å¹¶è§„èŒƒåŒ–
        annotations = {}
        for item in result:
            if isinstance(item, dict) and "line" in item and "emotion" in item:
                line_idx = item["line"]
                emo = item["emotion"].lower().strip()
                if emo in EMOTION_TAGS:
                    annotations[line_idx] = emo
                else:
                    # æ¨¡ç³ŠåŒ¹é…ï¼šå¦‚æœ LLM è¿”å›äº†ä¸­æ–‡æˆ–å˜ä½“
                    for tag in EMOTION_TAGS:
                        if tag in emo or emo in tag:
                            annotations[line_idx] = tag
                            break
                    else:
                        annotations[line_idx] = "neutral"  # æ— æ³•è¯†åˆ«åˆ™ fallback

        return annotations, None

    def annotate(self, dialogue_json, model, override_mode,
                 api_base_url="https://api.groq.com/openai/v1",
                 api_key_override="", custom_model=""):
        log = f"[{self.NODE_NAME}]"
        logs = []

        # è§£æ dialogue_json
        try:
            dialogue = json.loads(dialogue_json)
        except json.JSONDecodeError as e:
            error_msg = f"{log} JSON è§£æå¤±è´¥: {e}"
            print(error_msg)
            return (dialogue_json, error_msg)

        if not isinstance(dialogue, list):
            error_msg = f"{log} é”™è¯¯: dialogue_json ä¸æ˜¯åˆ—è¡¨"
            print(error_msg)
            return (dialogue_json, error_msg)

        # æ”¶é›†éœ€è¦æ ‡æ³¨çš„å¥å­
        speech_items = []
        speech_indices = []  # åœ¨ dialogue ä¸­çš„åŸå§‹ç´¢å¼•
        for i, item in enumerate(dialogue):
            if item.get("type") == "speech":
                existing_emotion = item.get("emotion")
                if override_mode == "overwrite_all" or not existing_emotion:
                    speech_items.append(item)
                    speech_indices.append(i)

        if not speech_items:
            msg = f"{log} æ‰€æœ‰å¥å­å·²æœ‰æƒ…æ„Ÿæ ‡æ³¨ï¼Œè·³è¿‡ (mode={override_mode})"
            print(msg)
            return (dialogue_json, msg)

        # æ„é€  prompt
        dialogue_lines = []
        for idx, item in enumerate(speech_items):
            speaker = item.get("speaker", "?")
            text = item.get("text", "")
            dialogue_lines.append(f"[{idx}] {speaker}: {text}")

        prompt = PROMPT_TEMPLATE.format(
            tags=", ".join(EMOTION_TAGS),
            lines="\n".join(dialogue_lines)
        )

        # è·å– API Key
        api_key = self._get_api_key(api_key_override)
        actual_model = custom_model.strip() if custom_model and custom_model.strip() else model
        actual_base = api_base_url.strip() if api_base_url else "https://api.groq.com/openai/v1"

        # é Groq çš„æœ¬åœ°æœåŠ¡å¯èƒ½ä¸éœ€è¦ key
        is_local = "localhost" in actual_base or "127.0.0.1" in actual_base
        if not api_key and not is_local:
            error_msg = (f"{log} æœªæ‰¾åˆ° API Keyã€‚è¯·è®¾ç½®ç¯å¢ƒå˜é‡ GROQ_API_KEY "
                         f"æˆ–åœ¨èŠ‚ç‚¹å‚æ•°ä¸­å¡«å…¥ api_key_override")
            print(error_msg)
            return (dialogue_json, error_msg)

        logs.append(f"æ¨¡å‹: {actual_model}")
        logs.append(f"API: {actual_base}")
        logs.append(f"å¾…æ ‡æ³¨: {len(speech_items)} å¥")
        print(f"{log} æ­£åœ¨è°ƒç”¨ LLM ({actual_model}) æ ‡æ³¨ {len(speech_items)} å¥æƒ…æ„Ÿ...")

        # è°ƒç”¨ LLM
        raw_response, api_error = self._call_llm(actual_base, api_key, actual_model, prompt)

        if api_error:
            error_msg = f"{log} API è°ƒç”¨å¤±è´¥: {api_error}"
            print(error_msg)
            logs.append(f"âŒ API é”™è¯¯: {api_error}")
            return (dialogue_json, "\n".join(logs))

        # è§£æå“åº”
        annotations, parse_error = self._parse_llm_response(raw_response, len(speech_items))

        if parse_error:
            error_msg = f"{log} å“åº”è§£æå¤±è´¥: {parse_error}"
            print(error_msg)
            logs.append(f"âŒ è§£æé”™è¯¯: {parse_error}")
            logs.append(f"åŸå§‹å“åº”: {raw_response[:300]}")
            return (dialogue_json, "\n".join(logs))

        # åˆå¹¶æƒ…æ„Ÿæ ‡æ³¨åˆ° dialogue_json
        annotated_count = 0
        for local_idx, emo in annotations.items():
            if local_idx < len(speech_indices):
                global_idx = speech_indices[local_idx]
                tag = EMOTION_TO_TAG.get(emo)
                if tag:  # neutral = None â†’ ä¸æ³¨å…¥
                    dialogue[global_idx]["emotion"] = tag
                    annotated_count += 1
                    display = EMOTION_DISPLAY.get(emo, emo)
                    speaker = dialogue[global_idx].get("speaker", "?")
                    text_preview = dialogue[global_idx].get("text", "")[:20]
                    logs.append(f"  [{tag}] {speaker}: {text_preview}...")
                else:
                    # neutral: æ¸…é™¤å·²æœ‰æ ‡ç­¾ï¼ˆå¦‚æœæ˜¯ overwrite æ¨¡å¼ï¼‰
                    if override_mode == "overwrite_all":
                        dialogue[global_idx]["emotion"] = None

        logs.insert(0, f"âœ… æ ‡æ³¨å®Œæˆ: {annotated_count}/{len(speech_items)} å¥è·å¾—æƒ…æ„Ÿæ ‡ç­¾")
        summary = "\n".join(logs)
        print(f"{log} {logs[0]}")

        result_json = json.dumps(dialogue, ensure_ascii=False, indent=2)
        return (result_json, summary)


# --- ComfyUI èŠ‚ç‚¹æ³¨å†Œ ---
NODE_CLASS_MAPPINGS = {
    "AIIA_Emotion_Annotator": AIIA_Emotion_Annotator,
}
NODE_DISPLAY_NAME_MAPPINGS = {
    "AIIA_Emotion_Annotator": "ğŸ­ AIIA Emotion Annotator (LLM)",
}
